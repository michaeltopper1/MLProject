---
title: "Cleaning"
author: "Michael Topper and Danny Klinenberg"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(fastDummies)
library(ROCR)
library(class)
df = board_games <- readr::read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-12/board_games.csv")

theme_set(theme_bw())
```


Exploratory Data Analysis
```{r}
df %>% ggplot(aes(average_rating)) +
  geom_histogram()


df %>% 
  mutate(above7 = as.factor(ifelse(average_rating >= 7, 1, 0))) %>% 
  count(above7)

df %>% count(publisher, sort = T)

df %>% 
  count(year_published) %>% 
  arrange(desc(year_published)) %>% 
  ggplot(aes(year_published, n)) +
  geom_line() 


df %>% filter(max_playtime < 1000) %>% ggplot(aes(max_playtime)) + 
  geom_histogram()

df %>% filter(max_playtime < 1000) %>% distinct(max_playtime) 
```

Finding the top types of games that are created. 
```{r}
catvars = df %>% 
  select(game_id, name, family, expansion, category, artist, designer, average_rating) %>% 
  gather(type, value, -game_id, -name) %>% 
  filter(!is.na(value)) %>% 
  separate_rows(value, sep = ',') %>% 
  arrange(game_id)

catcounts = catvars %>% 
  count(type, value,  sort = T)

catcounts %>% 
  filter(type == 'category') %>% 
  mutate(value = fct_reorder(value, n)) %>% 
  top_n(20, n) %>% 
  ggplot(aes(value, n)) +
  geom_col() +
  coord_flip() +
  ylab("Total") +
  xlab("Board Game Type") +
  labs(title = "Most Popular Types of Board Games")
```






Making a bar graph of decade 
```{r}
df %>% mutate(decade = 10 * (year_published %/% 10)) %>% 
  group_by(decade) %>% summarise(min_average_players = mean(min_players), avgdecaderating = mean(average_rating)) %>%
  ggplot(aes(x = decade, y = avgdecaderating)) + 
  geom_point() + 
  geom_smooth(method = 'lm') +
  labs(title = "Average Decade Rating Over Time") +
  xlab("Decade") +
  ylab("Average Rating in the Decade") +
  theme(plot.title = element_text(hjust = 0.5)) 


```

Designers by decade.
```{r}
df %>% mutate(decade = 10 * (year_published %/% 10)) %>% 
  filter(decade > 1950) %>% 
  filter(designer != '(Uncredited)') %>% 
  group_by(decade) %>% 
  count(designer, sort = T) %>%  
  filter(!is.na(designer)) %>% 
  arrange(desc(n)) %>% 
  top_n(5, n) %>% 
  ggplot(aes(x = designer, y = n, fill = as.factor(decade) )) +
  geom_col() +
  facet_wrap(~decade) +
  coord_flip() +
  labs(fill = "Decade", title = "Top 5 Designers by Decade") +
  xlab("Designer") +
  ylab("Count")

```


Publisher and mechanics
```{r}
mechanics = df %>% separate_rows(mechanic, sep = ",") %>% select(mechanic, game_id, publisher)

mechanics %>% 
  group_by(game_id) %>% count(mechanic, sort = T)
```


# Danny Cleaning

Let's just use the first mechanic the main mechanic and then count the number of expansions each game has
```{r data.make}
danny.dat<-df %>% 
  separate(.,mechanic, "mechanic1",sep=",",extra="drop") %>% #Just grabbing the first mechanic for our purposes 
  mutate(expansion1=ifelse(is.na(expansion),0,str_count(df$expansion,",")))
```
```{r expansion.relationship}
danny.dat %>%
  ggplot(., aes(I(log(expansion1+1)), average_rating))+
  geom_point()+
  geom_smooth()
```
Looks like more is better here. The relationship is a little funky but overall increasing. The relationship looks best as a log relationship. So I'm going to change expansion1 to that.

```{r data.clean}
danny.dat.use<-danny.dat %>% 
  mutate(expansion1=log(expansion1+1),
         decade = 10 * (year_published %/% 10),
         above7 = as.numeric(ifelse(average_rating >= 7, 1 , 0))
         ) %>% 
  select(c(above7,max_playtime,min_age,min_players,mechanic1,users_rated,expansion1,decade)) %>% 
  #dummy_cols(., remove_selected_columns = TRUE) %>%  #Couldn't get mechanic1 to register so have to do a trick
  mutate(above7=as.factor(above7)) %>% 
  drop_na()

#Some mechanics have like 1 observation in them. I'm going to drop convert mechanics with less than 20 into just "other"
cat.mut<-danny.dat.use %>% 
  group_by(mechanic1) %>% 
  summarise(n=n()) %>% 
  filter(n<20)

danny.dat.use<-danny.dat.use %>% 
  mutate(mechanic1=ifelse(mechanic1 %in% cat.mut$mechanic1, "other",mechanic1))

```

# Training and Testing

```{r train.test}
set.seed(4)

train<-sample(seq(1,dim(danny.dat.use)[1]), .5*dim(danny.dat.use)[1], replace = FALSE)
test<-sample(seq(1,dim(danny.dat.use)[1])[-train], .5*length(seq(1,dim(danny.dat.use)[1])[-train]), replace = FALSE)


train.dat<-danny.dat.use[train,]
test.dat<-danny.dat.use[test,]

#DO NOT TOUCH THIS UNTIL THE VERY VERY END. 
validation.dat<-danny.dat.use[-c(train,test),]

```

# Logistic Regression
```{r train.logit}
y.hat<-predict(glm(above7~.,data = train.dat, family = binomial(link="logit")), type="response")
cutoff<-function(p){
  return(as.numeric(y.hat>p))
}

mean(cutoff(.5)==train.dat$above7)
```

```{r train.cuttoff.graph}
hold<-tibble("cutoff"=seq(0,1,.01),
             "% correct"=rep(NA, length(seq(0,1,.01))))

for(i in seq_len(length(seq(0,1,.01)))){
  hold[i,2]<-mean(cutoff(hold$cutoff[i])==train.dat$above7)
}

ggplot(hold, aes(x=cutoff, y=`% correct`))+
  geom_point()+
  ggtitle("Cutoff vs % Correct: In sample")

```

Notice this is the in-sample best value. There is probably some overfitting going on. Now I will check with the test set.


```{r Logit.ROC.AUC}
glm.fit<-glm(above7~.,data = train.dat, family = binomial(link="logit"))
prob.training<-predict(glm.fit, type="response")

prob.test<-round(predict(glm.fit, test.dat, type="response"),digits=5) 

test.dat %>% 
  mutate(Prob=prob.test)

pred<-prediction(prob.training, train.dat$above7)
perf<-performance(pred, measure = "tpr",x.measure = "fpr")
plot(perf, col=2, lwd=3, main="ROC curve")
abline(0,1)

#AUC value
auc<-performance(pred, "auc")@y.values
auc

# Obtaining best cutoff value:

fpr = performance(pred, "fpr")@y.values[[1]] 
cutoff = performance(pred, "fpr")@x.values[[1]] # FNR 
fnr = performance(pred,"fnr")@y.values[[1]]

matplot(cutoff, cbind(fpr,fnr), type="l",lwd=2, xlab="Threshold",ylab="Error Rate") # Add legend to the plot 
legend(0.3, 1, legend=c("False Positive Rate","False Negative Rate"), col=c(1,2), lty=c(1,2))


rate = as.data.frame(cbind(Cutoff=cutoff, FPR=fpr, FNR=fnr)) 
rate$distance = sqrt((rate[,2])^2+(rate[,3])^2)

index = which.min(rate$distance) 
best = rate$Cutoff[index] 
best 

best.pred<-mean(as.numeric(prob.test>best)==test.dat$above7)
```

The best value to use as a cutoff is `r best` with a  success rate of `r best.pred`. This is the best cutoff value using the test set.

# KNN

```{r KNN.setup}
Ytrain<-train.dat$above7
Xtrain<-train.dat %>% select(-above7) %>% 
  dummy_cols(., remove_selected_columns = TRUE)
Xtrain<-scale(Xtrain,center=TRUE, scale = TRUE)

Ytest<-test.dat$above7
Xtest<-test.dat %>% 
  select(-above7) %>% 
  dummy_cols(., remove_selected_columns = TRUE) %>% 
  scale(center=TRUE, scale=TRUE)

```

Set up training success rate.
```{r KNN.train.2}
pred.ytrain<-knn(train=Xtrain, test=Xtrain, cl=Ytrain, k=2)

conf.train<-table(predicted=pred.ytrain,observed=Ytrain)

conf.train

#Train accuracy
sum(diag(conf.train)/sum(conf.train))
```

Now trying with the test set

```{r KNN.test.2}
pred.ytest<-knn(train=Xtrain, test=Xtest, cl=Ytrain, k=2)

conf.test<-table(predicted=pred.ytest,observed=Ytest)

conf.test

#Train accuracy
sum(diag(conf.test)/sum(conf.test))
```

With a nearest neighbor of 2, we can get the test success rate up to `r sum(diag(conf.test)/sum(conf.test))`.

Now, I will do a cross validation to figure out which number of neighbors I should use.  
```{r KNN.cv}
validation.error<-NULL
allK<-1:50
set.seed(66)

for (i in allK){ # Loop through different number of neighbors
  pred.Yval = knn.cv(train=Xtrain, cl=Ytrain, k=i) # Predict on the left-out validation set
  validation.error =c(validation.error, mean(pred.Yval!=Ytrain)) # Combine all validation errors 
  }

numneighbor = max(allK[validation.error == min(validation.error)]) 

numneighbor
```
Using LOOCV, we have determined the optimal number of neighbors is `r numneighbor`. Now, we will rerun the analysis on the test data using `r numneighbor` nearest neighbors.

```{r KNN.actual}
set.seed(67)

pred.YTest = knn(train=Xtrain, test=Xtest, cl=Ytrain, k=numneighbor)

conf.matrix = table(predicted=pred.YTest, true=Ytest) 
conf.matrix

sum(diag(conf.matrix)/sum(conf.matrix))
```

KNN gives us a slightly higher prediction rate than logistic regression.